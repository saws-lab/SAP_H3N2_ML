{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63011fc",
   "metadata": {},
   "source": [
    "# Optimize hyperparameters of XGBoost for each mutation matrix\n",
    "We will optimize hyperparameters of the eXtreme Gradient Boosting (XGBoost) model for each mutation matrix. The optimization will be based on the MAE performance of model over four validation seasons from 2012NH to 2013SH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd57cb7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07094155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "\n",
    "# self defined functions\n",
    "import utilities\n",
    "\n",
    "# for model development\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# for hyperparameter optimization\n",
    "from hyperopt import Trials, tpe, hp, fmin, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# for reproduciblility, fix the randomly generated numbers\n",
    "SEED = 100\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e570",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_Seasons = ['2012NH', '2012SH', '2013NH', '2013SH'] # seasons from 2012NH to 2013SH\n",
    "\n",
    "HA1_features  = [f\"HA1_{x}\" for x in range(1,329+1)]\n",
    "meta_features = [\n",
    "                 'virus',   # virus avidity\n",
    "                 'serum',   # antiserum potency\n",
    "                 'virusPassCat',\n",
    "                 'serumPassCat'\n",
    "                 ]   # metadata features\n",
    "\n",
    "metadata   = 'a+p+vPC+sPC'   # label to record which metadata is being used\n",
    "model_name = 'XGBoost'   # identifier for the type of model to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c340e81",
   "metadata": {},
   "source": [
    "## Paths and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_data   = \"../data/\"   # path of data\n",
    "path_result = \"../results/SuppFig6_comparison/\"   # results will be saved in this directory\n",
    "Path(path_result+f\"/hyperopt_trials_{model_name}/\").mkdir(parents=True, exist_ok=True)   # make directory if it does not exist already\n",
    "\n",
    "# filenames\n",
    "mut_mat_fn  = path_data + \"aaIndID_selected.txt\"   # filename of list of valid mutation matrics\n",
    "optimize_fn = path_result+f\"SuppFig6_optimize_{model_name}_mut_mat_hyperopt.csv\"   # to save optimization results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a65cab",
   "metadata": {},
   "source": [
    "## Read valid mutation matrices used for encoding genetic difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29600f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_mat_List = ['GIAG010101', 'AZAE970101', 'KOSJ950115', 'KOSJ950112', 'KOSJ950102',\n",
    "                'WEIL970102', 'MIYT790101', 'MUET010101', 'RUSR970101']\n",
    "\n",
    "# remaining\n",
    "mut_mat_List = ['KOSJ950115', 'KOSJ950112', 'KOSJ950102']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a3da7",
   "metadata": {},
   "source": [
    "## Indices of training and validation datasets for validation seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset temporarily\n",
    "dummy = pd.read_csv(path_data+\"nhts_ha1_binary.csv\",\n",
    "                    converters={\"seq_diff\": literal_eval})\n",
    "\n",
    "# to collect train and valid indices for each validation season\n",
    "indices_folds = []\n",
    "\n",
    "# loop through each validation season\n",
    "for valid_season in Valid_Seasons:\n",
    "    '''\n",
    "    Train Test Split\n",
    "        - based on seasonal framework\n",
    "        - Train: past virus isolates paired with past sera\n",
    "        - Test: circulating virus isolates paired with past sera\n",
    "    '''\n",
    "    ind_train, ind_valid = utilities.seasonal_trainTestSplit(dummy.copy(), valid_season)\n",
    "    \n",
    "    indices_folds.append((ind_train, ind_valid))\n",
    "\n",
    "del dummy, ind_train, ind_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b1779",
   "metadata": {},
   "source": [
    "## Objective function for hyperopt\n",
    "The objective is to minimize the average MAE over validation seasons. This function will train the RF model with provided hyperparameters and return the average MAE.\n",
    "\n",
    "> **Parameters**\n",
    "> - params (dict): dictionary of hyperparameters and corresponding values\n",
    "\n",
    "> **Returns**\n",
    "> - avg_mae (float): MAE averaged over validation seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b88bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    actual_all  = []   # to collect measured NHTs across validation seasons\n",
    "    predict_all = []   # to collect predicted NHTs across validation seasons\n",
    "    \n",
    "    # loop through validation seasons\n",
    "    for ind_train, ind_valid in indices_folds:\n",
    "        '''\n",
    "        Assign training and validation datasets\n",
    "        '''\n",
    "        # training dataset\n",
    "        data_train = data.iloc[ind_train].copy()\n",
    "        data_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # validation dataset\n",
    "        data_valid = data.iloc[ind_valid].copy()\n",
    "        data_valid.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Input features (genetic difference)\n",
    "        '''\n",
    "        # training dataset\n",
    "        X_train = pd.DataFrame(data_train.seq_diff.to_list(),\n",
    "                               index=data_train.index,\n",
    "                               columns=HA1_features)\n",
    "        X_train.fillna(0, inplace=True)   # replace nan with 0\n",
    "\n",
    "        # validation dataset\n",
    "        X_valid = pd.DataFrame(data_valid.seq_diff.to_list(),\n",
    "                               index=data_valid.index,\n",
    "                               columns=HA1_features)\n",
    "        X_valid.fillna(0, inplace=True)   # replace nan with 0\n",
    "\n",
    "\n",
    "        '''\n",
    "        Input features (metadata features)\n",
    "        '''\n",
    "        X_train_meta = data_train[meta_features].fillna('None').astype('str')\n",
    "        X_valid_meta = data_valid[meta_features].fillna('None').astype('str')\n",
    "\n",
    "\n",
    "        # one hot encoding\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        X_train_meta = ohe.fit_transform(X_train_meta).toarray()\n",
    "        X_valid_meta = ohe.transform(X_valid_meta).toarray()\n",
    "\n",
    "        X_train = np.hstack((X_train.values, X_train_meta))\n",
    "        X_valid = np.hstack((X_valid.values, X_valid_meta))\n",
    "\n",
    "\n",
    "        del X_train_meta, X_valid_meta\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Training and validation\n",
    "        '''\n",
    "        model = XGBRegressor(**params, booster='gbtree',\n",
    "                             n_jobs=-1, random_state = SEED)\n",
    "        model.fit(X_train, data_train.nht.values, verbose=False)\n",
    "        predict_valid = model.predict(X_valid)\n",
    "        \n",
    "        '''\n",
    "        save actuals and predictions\n",
    "        '''\n",
    "        actual_all.append(data_valid.nht.values)\n",
    "        predict_all.append(predict_valid)\n",
    "        \n",
    "        ##################\n",
    "        # End seasons loop\n",
    "        ##################\n",
    "    \n",
    "    actuals     = np.concatenate(actual_all)\n",
    "    predictions = np.concatenate(predict_all)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    metric or loss (MAE)\n",
    "    '''\n",
    "    avg_mae = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    return avg_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188636c",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5eb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loop through mutation matrices\n",
    "'''\n",
    "for mut_mat in mut_mat_List:\n",
    "    \n",
    "    print(\"Mutation matrix: \", mut_mat)\n",
    "    \n",
    "    '''\n",
    "    Dataset\n",
    "    '''\n",
    "    # Genetic difference (seq_diff) encoded as per the mutation matrix\n",
    "    # Converter is used to load the genetic difference saved as a list of floats\n",
    "    data = pd.read_csv(path_data+f\"nhts_ha1_{mut_mat}.csv\",\n",
    "                       converters={\"seq_diff\": literal_eval})\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Hyper-parameter optimization\n",
    "    '''\n",
    "    try:\n",
    "        '''\n",
    "        load the trials object\n",
    "        '''\n",
    "        with open(path_result+f\"hyperopt_trials_{model_name}/trials_{mut_mat}.hyperopt\", \"rb\") as f:\n",
    "            trial     = pickle.load(f)\n",
    "            max_evals = len(trial) + 5\n",
    "    except:\n",
    "        # hyperopt initialize trials object\n",
    "        trial = Trials()\n",
    "        max_evals = 100\n",
    "    \n",
    "    # hyperparameters search space\n",
    "    space={'n_estimators': scope.int(hp.uniform('n_estimators', 10, 500)),\n",
    "           'max_depth': scope.int(hp.uniform('max_depth', 2, 100)),\n",
    "           'subsample': scope.float(hp.uniform('subsample', 0.1, 1)),\n",
    "           'learning_rate': scope.float(hp.uniform('learning_rate', 0.001, 1)),\n",
    "           'colsample_bylevel': scope.float(hp.uniform('colsample_bylevel', 0.1, 1)),\n",
    "           'colsample_bytree': scope.float(hp.uniform('colsample_bytree', 0.1, 1)),\n",
    "          }\n",
    "    \n",
    "    # hyperopt minimization\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals, \n",
    "                trials=trial,\n",
    "                rstate=np.random.default_rng(SEED))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Best hyperparameters\n",
    "    '''\n",
    "    hyperparams = {'model': model_name,\n",
    "                   'metadata': metadata,\n",
    "                   'mut_mat': mut_mat,\n",
    "                   'mae': trial.best_trial['result']['loss']}\n",
    "    hyperparams.update(space_eval(space, best))\n",
    "    print(hyperparams)\n",
    "    \n",
    "    utilities.saveDict2CSV([hyperparams], optimize_fn)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    save the trials object\n",
    "    '''\n",
    "    with open(path_result+f\"hyperopt_trials_{model_name}/trials_{mut_mat}.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trial, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b14ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seasonal_ag_pred_tf]",
   "language": "python",
   "name": "conda-env-seasonal_ag_pred_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
