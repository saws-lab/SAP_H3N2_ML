{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63011fc",
   "metadata": {},
   "source": [
    "# Optimize hyperparameters of ResNet for each mutation matrix\n",
    "We will optimize hyperparameters of the Residual neural Network (ResNet) model for each mutation matrix. The optimization will be based on the MAE performance of model over four validation seasons from 2012NH to 2013SH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd57cb7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07094155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# self defined functions\n",
    "import utilities\n",
    "\n",
    "# for model development\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, ReLU, Add, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# for hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# for reproduciblility, fix the randomly generated numbers\n",
    "SEED = 100\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e570",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "752e19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_Seasons = ['2012NH', '2012SH', '2013NH', '2013SH'] # seasons from 2012NH to 2013SH\n",
    "\n",
    "HA1_features  = [f\"HA1_{x}\" for x in range(1,329+1)]\n",
    "meta_features = [\n",
    "                 'virus',   # virus avidity\n",
    "                 'serum',   # antiserum potency\n",
    "                 'virusPassCat',\n",
    "                 'serumPassCat'\n",
    "                 ]   # metadata features\n",
    "\n",
    "metadata   = 'a+p+vPC+sPC'   # label to record which metadata is being used\n",
    "model_name = 'ResNet'   # identifier for the type of model to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c340e81",
   "metadata": {},
   "source": [
    "## Paths and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "672fb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_data   = \"../data/\"   # path of data\n",
    "path_result = \"../results/SuppFig6_comparison/\"   # results will be saved in this directory\n",
    "Path(path_result+f\"/optuna_{model_name}/\").mkdir(parents=True, exist_ok=True)   # make directory if it does not exist already\n",
    "\n",
    "# filenames\n",
    "mut_mat_fn  = path_data + \"aaIndID_selected.txt\"   # filename of list of valid mutation matrics\n",
    "optimize_fn = path_result+f\"SuppFig6_optimize_{model_name}_mut_mat_optuna.csv\"   # to save optimization results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a65cab",
   "metadata": {},
   "source": [
    "## Read valid mutation matrices used for encoding genetic difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c29600f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_mat_List = ['AZAE970101']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a3da7",
   "metadata": {},
   "source": [
    "## Indices of training and validation datasets for validation seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b42854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset temporarily\n",
    "dummy = pd.read_csv(path_data+\"nhts_ha1_binary.csv\",\n",
    "                    converters={\"seq_diff\": literal_eval})\n",
    "\n",
    "# to collect train and valid indices for each validation season\n",
    "indices_folds = []\n",
    "\n",
    "# loop through each validation season\n",
    "for valid_season in Valid_Seasons:\n",
    "    '''\n",
    "    Train Test Split\n",
    "        - based on seasonal framework\n",
    "        - Train: past virus isolates paired with past sera\n",
    "        - Test: circulating virus isolates paired with past sera\n",
    "    '''\n",
    "    ind_train, ind_valid = utilities.seasonal_trainTestSplit(dummy.copy(), valid_season)\n",
    "    \n",
    "    indices_folds.append((ind_train, ind_valid))\n",
    "\n",
    "del dummy, ind_train, ind_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0b5b4",
   "metadata": {},
   "source": [
    "## Objective function for optuna\n",
    "The objective is to minimize the average MAE over validation seasons. For a single trial of optuna, this function will train the model using following hyperparameters (with their auto-selected values) and return the average MAE.\n",
    "- learning_rate (float):  learning rate of the optimizer\n",
    "- epochs (int): number of epochs\n",
    "- n_units_linear (int): number of units/neurons in first linear layer\n",
    "- n_resnet_blocks (int): number of layers of ResNetBlocks\n",
    "- units_rnb (int): number of units in ResNetBlock non-linear layer\n",
    "- dropout_rnb (float): dropout ratio\n",
    "- residual_dropout_rnb (float): residual dropout ratio after addition of input\n",
    "\n",
    "> **Parameters**\n",
    "> - trial object of optuna\n",
    "\n",
    "> **Returns**\n",
    "> - avg_mae (float): MAE averaged over validation seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dab0a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    actual_all  = []   # to collect measured NHTs across validation seasons\n",
    "    predict_all = []   # to collect predicted NHTs across validation seasons\n",
    "    \n",
    "    # loop through validation seasons\n",
    "    for ind_train, ind_valid in indices_folds:\n",
    "        '''\n",
    "        Assign training and validation datasets\n",
    "        '''\n",
    "        # training dataset\n",
    "        data_train = data.iloc[ind_train].copy()\n",
    "        data_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # validation dataset\n",
    "        data_valid = data.iloc[ind_valid].copy()\n",
    "        data_valid.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Input features (genetic difference)\n",
    "        '''\n",
    "        # training dataset\n",
    "        X_train = pd.DataFrame(data_train.seq_diff.to_list(),\n",
    "                               index=data_train.index,\n",
    "                               columns=HA1_features)\n",
    "        X_train.fillna(0, inplace=True)   # replace nan with 0\n",
    "\n",
    "        # validation dataset\n",
    "        X_valid = pd.DataFrame(data_valid.seq_diff.to_list(),\n",
    "                               index=data_valid.index,\n",
    "                               columns=HA1_features)\n",
    "        X_valid.fillna(0, inplace=True)   # replace nan with 0\n",
    "\n",
    "\n",
    "        '''\n",
    "        Input features (metadata features)\n",
    "        '''\n",
    "        X_train_meta = data_train[meta_features].fillna('None').astype('str')\n",
    "        X_valid_meta = data_valid[meta_features].fillna('None').astype('str')\n",
    "\n",
    "\n",
    "        # one hot encoding\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        X_train_meta = ohe.fit_transform(X_train_meta).toarray()\n",
    "        X_valid_meta = ohe.transform(X_valid_meta).toarray()\n",
    "\n",
    "        X_train = np.hstack((X_train.values, X_train_meta))\n",
    "        X_valid = np.hstack((X_valid.values, X_valid_meta))\n",
    "\n",
    "\n",
    "        del X_train_meta, X_valid_meta\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Scaling\n",
    "        '''\n",
    "        # Input normalization\n",
    "        normalizer = MinMaxScaler()\n",
    "        X_train    = normalizer.fit_transform(X_train)\n",
    "        X_valid    = normalizer.transform(X_valid)\n",
    "        \n",
    "        # target reshaping\n",
    "        y_train = data_train.nht.values.reshape(-1, 1)\n",
    "        y_valid = data_valid.nht.values.reshape(-1, 1)\n",
    "        \n",
    "        del data_train, data_valid\n",
    "        gc.collect()\n",
    "        \n",
    "        '''\n",
    "        Model\n",
    "        '''\n",
    "        # hyperparameters for optimization\n",
    "        learning_rate  = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        epochs         = trial.suggest_int(\"epochs\", 10, 200, step=10)\n",
    "        n_units_linear = trial.suggest_int(\"n_units_linear\", 100, 5000, step=100)\n",
    "        \n",
    "        # input to the model\n",
    "        input1 = Input(shape=(X_train.shape[1],))\n",
    "        \n",
    "        # initial Linear layer\n",
    "        x1 = Dense(n_units_linear)(input1)\n",
    "        \n",
    "        # ResNetBlocks\n",
    "        n_resnet_blocks = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "        \n",
    "        for resnet_block in range(1, n_resnet_blocks+1):\n",
    "            # hyperparameters for optimization\n",
    "            units_rnb            = trial.suggest_int(f\"n_units_rnb_{resnet_block}\", 100, 5000, step=100)\n",
    "            dropout_rnb          = trial.suggest_float(f\"dropout_rnb_{resnet_block}\", 0.0, 0.5, step=0.1)\n",
    "            residual_dropout_rnb = trial.suggest_float(f\"res_dropout_rnb_{resnet_block}\", 0.0, 0.5, step=0.1)\n",
    "        \n",
    "            x1 = BatchNormalization()(x1)\n",
    "            x1 = Dense(units_rnb, activation='relu')(x1)\n",
    "            x1 = Dropout(dropout_rnb)(x1)\n",
    "            x1 = Dense(X_train.shape[1])(x1)\n",
    "            x1 = Dropout(residual_dropout_rnb)(x1)\n",
    "            x1 = Add()([x1, input1])\n",
    "        \n",
    "        # Prediction block\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = ReLU()(x1)\n",
    "        x1 = Dense(1)(x1)\n",
    "        \n",
    "        model = tf.keras.models.Model(inputs=input1, outputs = x1)\n",
    "        model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "                     )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Training and validation\n",
    "        '''\n",
    "        model.fit(X_train, y_train,\n",
    "                  epochs = epochs,\n",
    "                  batch_size = 1024,\n",
    "                  shuffle = True,\n",
    "                  verbose=0\n",
    "                 )\n",
    "        predict_valid = model.predict(X_valid, verbose=0).squeeze()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        save actuals and predictions\n",
    "        '''\n",
    "        actual_all.append(y_valid.squeeze())\n",
    "        predict_all.append(predict_valid)\n",
    "        \n",
    "        ##################\n",
    "        # End seasons loop\n",
    "        ##################\n",
    "    \n",
    "    actuals     = np.concatenate(actual_all)\n",
    "    predictions = np.concatenate(predict_all)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    metric or loss (MAE)\n",
    "    '''\n",
    "    avg_mae = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    return avg_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188636c",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf5eb91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation matrix:  AZAE970101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 01:27:08,242] A new study created in memory with name: no-name-a49db103-11fd-4318-af4e-f1d229269632\n",
      "[I 2023-10-08 01:37:25,358] Trial 0 finished with value: 0.9863022943761699 and parameters: {'learning_rate': 0.0017359564480423334, 'epochs': 110, 'n_units_linear': 3900, 'n_layers': 4, 'n_units_rnb_1': 2600, 'dropout_rnb_1': 0.30000000000000004, 'res_dropout_rnb_1': 0.4, 'n_units_rnb_2': 2400, 'dropout_rnb_2': 0.2, 'res_dropout_rnb_2': 0.5, 'n_units_rnb_3': 1800, 'dropout_rnb_3': 0.5, 'res_dropout_rnb_3': 0.2, 'n_units_rnb_4': 2100, 'dropout_rnb_4': 0.1, 'res_dropout_rnb_4': 0.1}. Best is trial 0 with value: 0.9863022943761699.\n",
      "[I 2023-10-08 01:47:50,074] Trial 1 finished with value: 0.9588899217906008 and parameters: {'learning_rate': 0.013587720872108043, 'epochs': 110, 'n_units_linear': 2500, 'n_layers': 3, 'n_units_rnb_1': 3900, 'dropout_rnb_1': 0.5, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 5000, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.1, 'n_units_rnb_3': 1900, 'dropout_rnb_3': 0.1, 'res_dropout_rnb_3': 0.1}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 01:57:11,086] Trial 2 finished with value: 1.0324040017254765 and parameters: {'learning_rate': 0.003588131511261406, 'epochs': 120, 'n_units_linear': 200, 'n_layers': 4, 'n_units_rnb_1': 1900, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3900, 'dropout_rnb_2': 0.30000000000000004, 'res_dropout_rnb_2': 0.5, 'n_units_rnb_3': 1300, 'dropout_rnb_3': 0.1, 'res_dropout_rnb_3': 0.30000000000000004, 'n_units_rnb_4': 4300, 'dropout_rnb_4': 0.5, 'res_dropout_rnb_4': 0.1}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:01:19,440] Trial 3 finished with value: 1.992694831699795 and parameters: {'learning_rate': 5.935150143852892e-05, 'epochs': 120, 'n_units_linear': 4300, 'n_layers': 1, 'n_units_rnb_1': 1500, 'dropout_rnb_1': 0.5, 'res_dropout_rnb_1': 0.2}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:03:36,382] Trial 4 finished with value: 2.477184161146426 and parameters: {'learning_rate': 1.660649895388452e-05, 'epochs': 100, 'n_units_linear': 2100, 'n_layers': 1, 'n_units_rnb_1': 1500, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.5}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:10:07,502] Trial 5 finished with value: 1.0767090294048136 and parameters: {'learning_rate': 9.454918228132256e-05, 'epochs': 120, 'n_units_linear': 2800, 'n_layers': 3, 'n_units_rnb_1': 1800, 'dropout_rnb_1': 0.30000000000000004, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 2400, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.0, 'n_units_rnb_3': 1100, 'dropout_rnb_3': 0.5, 'res_dropout_rnb_3': 0.1}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:21:05,917] Trial 6 finished with value: 1.6541308570447046 and parameters: {'learning_rate': 1.4379841782242358e-05, 'epochs': 140, 'n_units_linear': 1300, 'n_layers': 3, 'n_units_rnb_1': 2800, 'dropout_rnb_1': 0.30000000000000004, 'res_dropout_rnb_1': 0.0, 'n_units_rnb_2': 4800, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.5, 'n_units_rnb_3': 3200, 'dropout_rnb_3': 0.2, 'res_dropout_rnb_3': 0.4}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:32:52,059] Trial 7 finished with value: 1.796254319116392 and parameters: {'learning_rate': 0.00017069728292964546, 'epochs': 150, 'n_units_linear': 700, 'n_layers': 3, 'n_units_rnb_1': 4800, 'dropout_rnb_1': 0.30000000000000004, 'res_dropout_rnb_1': 0.4, 'n_units_rnb_2': 4500, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.4, 'n_units_rnb_3': 2500, 'dropout_rnb_3': 0.1, 'res_dropout_rnb_3': 0.4}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:33:56,710] Trial 8 finished with value: 1.101825647505481 and parameters: {'learning_rate': 0.006894521292031423, 'epochs': 30, 'n_units_linear': 800, 'n_layers': 3, 'n_units_rnb_1': 1100, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.4, 'n_units_rnb_2': 1700, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.2, 'n_units_rnb_3': 100, 'dropout_rnb_3': 0.1, 'res_dropout_rnb_3': 0.2}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:37:35,085] Trial 9 finished with value: 1.1295359058757424 and parameters: {'learning_rate': 0.08733701780173846, 'epochs': 50, 'n_units_linear': 2200, 'n_layers': 2, 'n_units_rnb_1': 3500, 'dropout_rnb_1': 0.30000000000000004, 'res_dropout_rnb_1': 0.30000000000000004, 'n_units_rnb_2': 4700, 'dropout_rnb_2': 0.1, 'res_dropout_rnb_2': 0.5}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 02:58:37,977] Trial 10 finished with value: 1.416537367292258 and parameters: {'learning_rate': 0.02603607291505045, 'epochs': 200, 'n_units_linear': 3400, 'n_layers': 5, 'n_units_rnb_1': 4900, 'dropout_rnb_1': 0.5, 'res_dropout_rnb_1': 0.0, 'n_units_rnb_2': 200, 'dropout_rnb_2': 0.0, 'res_dropout_rnb_2': 0.0, 'n_units_rnb_3': 3800, 'dropout_rnb_3': 0.30000000000000004, 'res_dropout_rnb_3': 0.0, 'n_units_rnb_4': 100, 'dropout_rnb_4': 0.4, 'res_dropout_rnb_4': 0.5, 'n_units_rnb_5': 700, 'dropout_rnb_5': 0.0, 'res_dropout_rnb_5': 0.5}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:09:08,116] Trial 11 finished with value: 1.385766562441636 and parameters: {'learning_rate': 0.0009434390381338685, 'epochs': 70, 'n_units_linear': 4800, 'n_layers': 5, 'n_units_rnb_1': 3300, 'dropout_rnb_1': 0.4, 'res_dropout_rnb_1': 0.30000000000000004, 'n_units_rnb_2': 3200, 'dropout_rnb_2': 0.2, 'res_dropout_rnb_2': 0.2, 'n_units_rnb_3': 2200, 'dropout_rnb_3': 0.5, 'res_dropout_rnb_3': 0.2, 'n_units_rnb_4': 1900, 'dropout_rnb_4': 0.0, 'res_dropout_rnb_4': 0.0, 'n_units_rnb_5': 4900, 'dropout_rnb_5': 0.5, 'res_dropout_rnb_5': 0.0}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:16:03,533] Trial 12 finished with value: 1.1149592169571114 and parameters: {'learning_rate': 0.0013523099899374164, 'epochs': 90, 'n_units_linear': 3500, 'n_layers': 4, 'n_units_rnb_1': 200, 'dropout_rnb_1': 0.4, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 1600, 'dropout_rnb_2': 0.2, 'res_dropout_rnb_2': 0.30000000000000004, 'n_units_rnb_3': 5000, 'dropout_rnb_3': 0.30000000000000004, 'res_dropout_rnb_3': 0.0, 'n_units_rnb_4': 2200, 'dropout_rnb_4': 0.1, 'res_dropout_rnb_4': 0.30000000000000004}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:37:10,755] Trial 13 finished with value: 1.1342342597135682 and parameters: {'learning_rate': 0.01241105437275947, 'epochs': 170, 'n_units_linear': 3800, 'n_layers': 4, 'n_units_rnb_1': 4100, 'dropout_rnb_1': 0.2, 'res_dropout_rnb_1': 0.5, 'n_units_rnb_2': 3000, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.1, 'n_units_rnb_3': 1600, 'dropout_rnb_3': 0.0, 'res_dropout_rnb_3': 0.1, 'n_units_rnb_4': 4100, 'dropout_rnb_4': 0.2, 'res_dropout_rnb_4': 0.2}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:41:18,328] Trial 14 finished with value: 1.153281214958765 and parameters: {'learning_rate': 0.0017336417951242381, 'epochs': 80, 'n_units_linear': 2800, 'n_layers': 2, 'n_units_rnb_1': 2600, 'dropout_rnb_1': 0.4, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 2000, 'dropout_rnb_2': 0.30000000000000004, 'res_dropout_rnb_2': 0.30000000000000004}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:44:45,723] Trial 15 finished with value: 1.295886211279771 and parameters: {'learning_rate': 0.0005580141622739326, 'epochs': 60, 'n_units_linear': 2000, 'n_layers': 4, 'n_units_rnb_1': 3900, 'dropout_rnb_1': 0.5, 'res_dropout_rnb_1': 0.4, 'n_units_rnb_2': 200, 'dropout_rnb_2': 0.1, 'res_dropout_rnb_2': 0.1, 'n_units_rnb_3': 300, 'dropout_rnb_3': 0.4, 'res_dropout_rnb_3': 0.1, 'n_units_rnb_4': 800, 'dropout_rnb_4': 0.30000000000000004, 'res_dropout_rnb_4': 0.30000000000000004}. Best is trial 1 with value: 0.9588899217906008.\n",
      "[I 2023-10-08 03:57:53,568] Trial 16 finished with value: 0.8892014375319341 and parameters: {'learning_rate': 0.0042337494414221325, 'epochs': 160, 'n_units_linear': 4300, 'n_layers': 2, 'n_units_rnb_1': 3200, 'dropout_rnb_1': 0.2, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3600, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.1}. Best is trial 16 with value: 0.8892014375319341.\n",
      "[I 2023-10-08 04:17:23,792] Trial 17 finished with value: 0.8890298436097646 and parameters: {'learning_rate': 0.021212198985872958, 'epochs': 180, 'n_units_linear': 5000, 'n_layers': 2, 'n_units_rnb_1': 4300, 'dropout_rnb_1': 0.2, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3900, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.1}. Best is trial 17 with value: 0.8890298436097646.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 04:39:08,039] Trial 18 finished with value: 0.9203784602764838 and parameters: {'learning_rate': 0.04561531910519763, 'epochs': 200, 'n_units_linear': 5000, 'n_layers': 2, 'n_units_rnb_1': 4400, 'dropout_rnb_1': 0.2, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3800, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.1}. Best is trial 17 with value: 0.8890298436097646.\n",
      "[I 2023-10-08 04:48:50,833] Trial 19 finished with value: 1.2300378359490702 and parameters: {'learning_rate': 0.005343436741534966, 'epochs': 170, 'n_units_linear': 4400, 'n_layers': 1, 'n_units_rnb_1': 3100, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.30000000000000004}. Best is trial 17 with value: 0.8890298436097646.\n",
      "[I 2023-10-08 05:05:49,980] Trial 20 finished with value: 0.864398197920666 and parameters: {'learning_rate': 0.029552605163529966, 'epochs': 170, 'n_units_linear': 4500, 'n_layers': 2, 'n_units_rnb_1': 4400, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3800, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 05:22:41,369] Trial 21 finished with value: 0.9530459769665929 and parameters: {'learning_rate': 0.024689535462466994, 'epochs': 170, 'n_units_linear': 4400, 'n_layers': 2, 'n_units_rnb_1': 4400, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3900, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 05:36:11,989] Trial 22 finished with value: 0.8881988277247256 and parameters: {'learning_rate': 0.08987508749110178, 'epochs': 150, 'n_units_linear': 4700, 'n_layers': 2, 'n_units_rnb_1': 3600, 'dropout_rnb_1': 0.2, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3300, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 05:53:50,307] Trial 23 finished with value: 0.9351564893595328 and parameters: {'learning_rate': 0.07077870736531157, 'epochs': 190, 'n_units_linear': 4900, 'n_layers': 2, 'n_units_rnb_1': 3700, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.30000000000000004, 'n_units_rnb_2': 3100, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:05:20,215] Trial 24 finished with value: 0.8783890424068324 and parameters: {'learning_rate': 0.03710394822535915, 'epochs': 140, 'n_units_linear': 5000, 'n_layers': 1, 'n_units_rnb_1': 4400, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:15:19,732] Trial 25 finished with value: 0.9130599122281818 and parameters: {'learning_rate': 0.09696431380002762, 'epochs': 140, 'n_units_linear': 3900, 'n_layers': 1, 'n_units_rnb_1': 4700, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:26:18,702] Trial 26 finished with value: 0.8738116683668794 and parameters: {'learning_rate': 0.04616633644409599, 'epochs': 140, 'n_units_linear': 4600, 'n_layers': 1, 'n_units_rnb_1': 4600, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:35:49,176] Trial 27 finished with value: 0.8666198120256882 and parameters: {'learning_rate': 0.04005205142735151, 'epochs': 140, 'n_units_linear': 3500, 'n_layers': 1, 'n_units_rnb_1': 4900, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:43:59,221] Trial 28 finished with value: 0.8733791979678679 and parameters: {'learning_rate': 0.03932927118958295, 'epochs': 130, 'n_units_linear': 3300, 'n_layers': 1, 'n_units_rnb_1': 4800, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:52:12,360] Trial 29 finished with value: 0.8774883817218057 and parameters: {'learning_rate': 0.010558964739928407, 'epochs': 130, 'n_units_linear': 3200, 'n_layers': 1, 'n_units_rnb_1': 4800, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 06:58:39,711] Trial 30 finished with value: 0.8712352739450043 and parameters: {'learning_rate': 0.016459546694612182, 'epochs': 100, 'n_units_linear': 3200, 'n_layers': 1, 'n_units_rnb_1': 5000, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:05:29,548] Trial 31 finished with value: 0.91237862738115 and parameters: {'learning_rate': 0.018711179546910345, 'epochs': 110, 'n_units_linear': 3100, 'n_layers': 1, 'n_units_rnb_1': 4900, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:16:39,935] Trial 32 finished with value: 0.8811500409901201 and parameters: {'learning_rate': 0.04148321779351129, 'epochs': 160, 'n_units_linear': 3600, 'n_layers': 1, 'n_units_rnb_1': 5000, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:23:06,238] Trial 33 finished with value: 0.890500659723459 and parameters: {'learning_rate': 0.009286364673238982, 'epochs': 100, 'n_units_linear': 4000, 'n_layers': 1, 'n_units_rnb_1': 4000, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:29:49,228] Trial 34 finished with value: 0.8759881259459342 and parameters: {'learning_rate': 0.01396851153884814, 'epochs': 120, 'n_units_linear': 2600, 'n_layers': 1, 'n_units_rnb_1': 5000, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:36:38,211] Trial 35 finished with value: 1.214696232496658 and parameters: {'learning_rate': 0.0029181558567328517, 'epochs': 110, 'n_units_linear': 3100, 'n_layers': 2, 'n_units_rnb_1': 4200, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0, 'n_units_rnb_2': 900, 'dropout_rnb_2': 0.0, 'res_dropout_rnb_2': 0.4}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:46:09,867] Trial 36 finished with value: 0.8712536604853625 and parameters: {'learning_rate': 0.028229880727074486, 'epochs': 130, 'n_units_linear': 4000, 'n_layers': 1, 'n_units_rnb_1': 4600, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 07:50:00,610] Trial 37 finished with value: 0.8985766605718758 and parameters: {'learning_rate': 0.0162104705873919, 'epochs': 90, 'n_units_linear': 4100, 'n_layers': 1, 'n_units_rnb_1': 2200, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:02:50,373] Trial 38 finished with value: 1.0072634201050867 and parameters: {'learning_rate': 0.007548370790373773, 'epochs': 130, 'n_units_linear': 3700, 'n_layers': 2, 'n_units_rnb_1': 4600, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 4400, 'dropout_rnb_2': 0.30000000000000004, 'res_dropout_rnb_2': 0.2}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:12:07,840] Trial 39 finished with value: 0.8769659192925005 and parameters: {'learning_rate': 0.026139483246784414, 'epochs': 150, 'n_units_linear': 4100, 'n_layers': 1, 'n_units_rnb_1': 3800, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:13:26,903] Trial 40 finished with value: 1.1759565457554415 and parameters: {'learning_rate': 0.05650593105970289, 'epochs': 20, 'n_units_linear': 2900, 'n_layers': 1, 'n_units_rnb_1': 4500, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:20:45,198] Trial 41 finished with value: 0.8669763318542804 and parameters: {'learning_rate': 0.032308222103672755, 'epochs': 130, 'n_units_linear': 3400, 'n_layers': 1, 'n_units_rnb_1': 4100, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:25:08,003] Trial 42 finished with value: 0.891123162747301 and parameters: {'learning_rate': 0.03270126031059187, 'epochs': 100, 'n_units_linear': 2400, 'n_layers': 1, 'n_units_rnb_1': 4000, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 08:32:52,765] Trial 43 finished with value: 0.8926524137774389 and parameters: {'learning_rate': 0.06353679518825933, 'epochs': 120, 'n_units_linear': 3500, 'n_layers': 1, 'n_units_rnb_1': 4600, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:40:34,220] Trial 44 finished with value: 1.1526099345515683 and parameters: {'learning_rate': 0.016292522987740934, 'epochs': 90, 'n_units_linear': 3800, 'n_layers': 2, 'n_units_rnb_1': 4200, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.0, 'n_units_rnb_2': 2700, 'dropout_rnb_2': 0.1, 'res_dropout_rnb_2': 0.4}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:51:29,930] Trial 45 finished with value: 1.2595668367128259 and parameters: {'learning_rate': 0.027886680891849026, 'epochs': 120, 'n_units_linear': 4100, 'n_layers': 3, 'n_units_rnb_1': 3000, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1, 'n_units_rnb_2': 900, 'dropout_rnb_2': 0.30000000000000004, 'res_dropout_rnb_2': 0.30000000000000004, 'n_units_rnb_3': 5000, 'dropout_rnb_3': 0.0, 'res_dropout_rnb_3': 0.5}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 08:56:42,175] Trial 46 finished with value: 1.0034974092672788 and parameters: {'learning_rate': 0.010673264859694819, 'epochs': 160, 'n_units_linear': 1800, 'n_layers': 1, 'n_units_rnb_1': 3400, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.0}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 09:12:09,682] Trial 47 finished with value: 0.966575781649859 and parameters: {'learning_rate': 0.06008851184812719, 'epochs': 180, 'n_units_linear': 2900, 'n_layers': 3, 'n_units_rnb_1': 2300, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.0, 'n_units_rnb_2': 4200, 'dropout_rnb_2': 0.2, 'res_dropout_rnb_2': 0.2, 'n_units_rnb_3': 4000, 'dropout_rnb_3': 0.4, 'res_dropout_rnb_3': 0.5}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 09:15:01,824] Trial 48 finished with value: 0.8830889833675962 and parameters: {'learning_rate': 0.019563422254564287, 'epochs': 130, 'n_units_linear': 3400, 'n_layers': 1, 'n_units_rnb_1': 900, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.1}. Best is trial 20 with value: 0.864398197920666.\n",
      "[I 2023-10-08 09:22:47,962] Trial 49 finished with value: 1.1129084999097143 and parameters: {'learning_rate': 0.0068507213792563925, 'epochs': 80, 'n_units_linear': 4500, 'n_layers': 2, 'n_units_rnb_1': 5000, 'dropout_rnb_1': 0.1, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 1100, 'dropout_rnb_2': 0.4, 'res_dropout_rnb_2': 0.30000000000000004}. Best is trial 20 with value: 0.864398197920666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'ResNet', 'metadata': 'a+p+vPC+sPC', 'mut_mat': 'AZAE970101', 'mae': 0.864398197920666, 'learning_rate': 0.029552605163529966, 'epochs': 170, 'n_units_linear': 4500, 'n_layers': 2, 'n_units_rnb_1': 4400, 'dropout_rnb_1': 0.0, 'res_dropout_rnb_1': 0.2, 'n_units_rnb_2': 3800, 'dropout_rnb_2': 0.5, 'res_dropout_rnb_2': 0.0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "loop through mutation matrices\n",
    "'''\n",
    "for mut_mat in mut_mat_List:\n",
    "    \n",
    "    print(\"Mutation matrix: \", mut_mat)\n",
    "    \n",
    "    '''\n",
    "    Dataset\n",
    "    '''\n",
    "    # Genetic difference (seq_diff) encoded as per the mutation matrix\n",
    "    # Converter is used to load the genetic difference saved as a list of floats\n",
    "    data = pd.read_csv(path_data+f\"nhts_ha1_{mut_mat}.csv\",\n",
    "                       converters={\"seq_diff\": literal_eval})\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Hyper-parameter optimization\n",
    "    '''\n",
    "    try:\n",
    "        '''\n",
    "        load the optuna study object\n",
    "        '''\n",
    "        with open(path_result+f\"optuna_{model_name}/study_{mut_mat}.optuna\", \"rb\") as f:\n",
    "            study     = pickle.load(f)\n",
    "            n_trials  = 5\n",
    "    except:\n",
    "        # hyperopt initialize trials object\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        n_trials = 50\n",
    "    \n",
    "    # optuna minimization\n",
    "    study.optimize(objective, n_trials=n_trials, gc_after_trial=True)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Best hyperparameters\n",
    "    '''\n",
    "    hyperparams = {'model': model_name,\n",
    "                   'metadata': metadata,\n",
    "                   'mut_mat': mut_mat,\n",
    "                   'mae': study.best_value\n",
    "                  }\n",
    "    hyperparams.update(study.best_params)\n",
    "    print(hyperparams)\n",
    "    \n",
    "    # save to CSV\n",
    "    utilities.saveDict2CSV([hyperparams], optimize_fn)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    save the trials object\n",
    "    '''\n",
    "    with open(path_result+f\"optuna_{model_name}/study_{mut_mat}.optuna\", \"wb\") as f:\n",
    "        pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608edde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seasonal_ag_pred]",
   "language": "python",
   "name": "conda-env-seasonal_ag_pred-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
